<!DOCTYPE html>
<html>
<head>
<title>Programació paral·lela amb mpi4py.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/*

Google Code style (c) Aahan Krish <geekpanth3r@gmail.com>

*/

.hljs {
  display: block;
  overflow-x: auto;
  padding: 0.5em;
  background: white;
  color: black;
}

.hljs-comment,
.hljs-quote {
  color: #800;
}

.hljs-keyword,
.hljs-selector-tag,
.hljs-section,
.hljs-title,
.hljs-name {
  color: #008;
}

.hljs-variable,
.hljs-template-variable {
  color: #660;
}

.hljs-string,
.hljs-selector-attr,
.hljs-selector-pseudo,
.hljs-regexp {
  color: #080;
}

.hljs-literal,
.hljs-symbol,
.hljs-bullet,
.hljs-meta,
.hljs-number,
.hljs-link {
  color: #066;
}

.hljs-title,
.hljs-doctag,
.hljs-type,
.hljs-attr,
.hljs-built_in,
.hljs-builtin-name,
.hljs-params {
  color: #606;
}

.hljs-attribute,
.hljs-subst {
  color: #000;
}

.hljs-formula {
  background-color: #eee;
  font-style: italic;
}

.hljs-selector-id,
.hljs-selector-class {
  color: #9B703F
}

.hljs-addition {
  background-color: #baeeba;
}

.hljs-deletion {
  background-color: #ffc8bd;
}

.hljs-doctag,
.hljs-strong {
  font-weight: bold;
}

.hljs-emphasis {
  font-style: italic;
}

</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="programaci%C3%B3-parallela-amb-mpi4py">Programació paral·lela amb mpi4py</h1>
<h2 id="1-el-pas-de-missatges">1. El pas de missatges</h2>
<p>Entre els diferents models de càlcul paral·lel, el <strong>Pas de Missatges</strong> va demostrar ser un dels més eficients. Aquest paradigma és especialment adequat per a arquitectures de memòria distribuïda. En aquest model, els fils es troben en una o més màquines i es comuniquen entre ells mitjançant missatges via Ethernet.</p>
<p><img src="./mpi4py-1.jpg" alt="Pas de misstge"></p>
<p>Aquest model es basa en un protocol específic anomenat <strong>MPI</strong> (<em>Message Passing Interface</em>). Consisteix principalment en un sistema portàtil i estandarditzat de transmissió de missatges, que actualment s’ha convertit en l’<em>estàndard de facto</em> per a la comunicació paral·lela dins dels clústers. Des del seu primer llançament, la biblioteca estàndard MPI s'ha convertit en la més estesa.</p>
<h2 id="11-enviar-i-rebre-objectes-python-amb-communicators">1.1 Enviar i rebre objectes Python amb <code>Communicators</code></h2>
<p>La interfície MPI per a Python implementa el model Message Passing mitjançant el protocol MPI. Per tant, la característica clau d'aquesta interfície és la <strong>possibilitat de enviar dades i ordres (objectes Python) entre sistemes</strong>. Darrere d’aquesta operació s’exploten les funcionalitats especials d’un mòdul anomenat <code>pickle</code>. Aquest mòdul us permet construir representacions binàries (<em>pickling</em>) de qualsevol objecte Python (tant integrat com definit per l'usuari). Aquestes representacions binàries es poden enviar entre sistemes, de manera que es poden intercanviar dades i instruccions necessàries per al càlcul paral·lel. Les representacions binàries un cop arribades al sistema, es restauren en la seva forma original, és a dir, l'objecte Python original (<em>unpickling</em>). Tot això serà transparent al programador, que</p>
<p>Aquesta opció també permet la comunicació entre sistemes heterogenis, és a dir, un clúster compost de sistemes amb diferents arquitectures. De fet, els objectes Python enviats com a representacions binàries poden ser reconstruïts pel sistema receptor d'acord amb la seva arquitectura particular.</p>
<p>A la biblioteca MPI, els diversos fils s’organitzen en grups anomenats <strong>comunicadors</strong>. Tots els fils d’un comunicador determinat poden parlar entre ells, però no amb fils externs.</p>
<p>L'objecte del mòdul mpi4py que implícitament realitza totes les funcions de comunicació és l'objecte <code>Comm</code>, que significa comunicador. Hi ha dues instàncies per defecte d'aquesta classe: <code>COMM_SELF</code> i <code>COMM_WORLD</code>.</p>
<p>A través d’ells podeu crear tots els nous comunicadors que necessiteu. De fet, quan s’activa el protocol MPI, es crea un comunicador per defecte que conté tots els fils disponibles. Per iniciar un MPI només cal importar el mòdul. A partir d'ahi, podem saber quants processos hi hauràn al clúster en aquest communicador (<code>comm.Get_size()</code>) i qui és l'actual proces (<code>comm.Get_size()</code>). Podem, ademés saber el nom del node que està executant aquest codi (<code>MPI.Get_processor_name()</code>)</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> mpi4py <span class="hljs-keyword">import</span> MPI

comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()
name = MPI.Get_processor_name()
</div></code></pre>
<h2 id="2-execuci%C3%B3-de-programes-parallels">2. Execució de programes paral·lels</h2>
<p>Quan executem un programa de manera paral·lela amb mpi, hem d'indicar 3 coses:</p>
<ul>
<li>Número de processos paral·lels que s'executaran</li>
<li>On s'executaran dits processos.</li>
<li>Programa que s'executa, amb els seus arguments, si en te.</li>
</ul>
<p>Així per exemple:</p>
<pre class="hljs"><code><div>mpiexec -np 8 -f machinefile python imageFilter.py Lenna.png
</div></code></pre>
<p>on:</p>
<ul>
<li>S'executen 8 processos,</li>
<li>el conjunt de màquines es descriu en l'arxiu <code>machinefile</code>, i conté linies amb el format <code>maquina[:cores]</code></li>
<li><code>python imageFilter.py Lenna.png</code> indica que carrega l'interpret de python per a filtrar la imatge <em>Lenna.bmp</em></li>
</ul>
<p>Llavors hem de tenir en comte que, seguint l'anterior, s'executaran 8 programes, repartits pel cluster, tots amb el mateix codi i variables. Què és el que canvia en cada programa, si tots tenen el mateix codi, molt senzil, la variable <code>rank</code>. Si hi han 8 programes en execució, <code>rank = comm.Get_rank()</code> retornarà a cadascun els valor <code>0..7</code>, amb la qual cosa podem diferenciar entre ells</p>
<h3 id="21-master-i-slave-algorismes-parallels">2.1 <em>master</em> i <em>slave</em>. Algorismes paral·lels</h3>
<p>A la programació paral·lela de entre tots els programes, la filosofia serà que algú ha d'encarregar de repartir la feina, fer-la entre tots, i desprès recopilar els resultats.</p>
<p>El node encarregat de repartir la tasca rep el rol de <code>master</code> o <code>root</code>. Habitualment serà <code>root</code> aquell node que compleix que <code>rank==0</code>
La resta seràn els que simplement rebran la tasca a fer de <code>root</code>, la faran i li donaran resposta:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">if</span> rank==<span class="hljs-number">0</span>:
    repartir les tasques

rebre la tasca de root

fer les tasques

enviar resultats a root

<span class="hljs-keyword">if</span> rank==<span class="hljs-number">0</span>:
    resumir/presentar els resultats
</div></code></pre>
<blockquote>
<p>Nota:</p>
<ul>
<li>Adonar-se que les tasques de repartir i rebre les dades sols les fa el màster</li>
<li>El master també és un treballador més, és a dir, posiblement també farà la seua part de tasca (o no, depenent de l'algorisme)</li>
</ul>
</blockquote>
<h2 id="3-tipus-de-comunicacions">3. Tipus de comunicacions</h2>
<p>Totes les comunicacions porten etiquetes (<code>tags</code>). Aquests proporcionen un mitjà de reconeixement per part del receptor perquè pugui entendre si ho ha de considerar o no, i de quina manera actuar.</p>
<p>Abans de començar a desenvolupar el codi, hem d'estudiar l'algoritme paral·lel que ens permetrà dur a terme el nostre projecte, i cal pensar quin tipus de comunicació implementar. De fet, hi ha dos tipus de comunicació: <strong>bloquejant</strong> i <strong>no bloquejant</strong>. Aquests dos tipus de comunicació difereixen segons com vulguem que es comportin els dos sistemes de comunicació.</p>
<h3 id="31-la-comunicaci%C3%B3-bloquejant-blocking">3.1 La comunicació bloquejant (<strong>Blocking</strong>)</h3>
<p>Generalment, les comunicacions que existeixen entre els diversos sistemes d’un clúster són bloquejants. Per tant, el programa remitent (qui envia) no continuarà mentre espere que el receptor reba la informació. Els mètodes <code>send()</code>, <code>recv()</code> i <code>sendrecv()</code> són els mètodes per comunicar objectes genèrics Python. Per permetre la transmissió de grans matrius de dades com la matriu <em>NumPy</em>  s’utilitzen mètodes com <code>Send()</code> i <code>Recv()</code> .</p>
<p>En aquest tipus de comunicacions, quan algun procés invoca a <code>recv()</code> es queda esperant a que algú li envie dades amb <code>send()</code>. De la mateuxa manera qui envia a <code>send()</code> es queda esperant a que el receptor ho reba amb <code>recv()</code>. Per tant per cada <code>send()</code> en algun lloc hi ha de hiaure un <code>recv()</code> en altre lloc. Sinó podem provocar situacions de bloquejos.</p>
<p>Per saber i classificar la informació que enviem i rebem, pot afergir-se un etiqueta o <code>tag</code> com a argument opcional, de manera que podem separar si el que hem rebut és una dada a processar o informació de control o un senyal per a acabar el programa</p>
<h1 id="exemple-suma-dun-vector-parallela">Exemple: Suma d'un vector paral·lela</h1>
<p>Tots sabem com es suma un vector. Amb un bucle for, des del primer fins a l'últim anem sumant i acumulant.</p>
<p>Imaginem que tenim un vector de 32000 enters. Com podriem fer paral·lel l'algorisme de sumar un vector, si tenim per exemple 8 o 16 programes en execució?</p>
<p>Resposta: Dividim el vector segons el numero de processos, i cada proces suma la seua part. Cada procés retorna la seua part de la suma i el node master l'arreplega de nou.</p>
<p><img src="./Suma_Vector.png" alt=""></p>
<h3 id="32-cal-enviar-ho-tot">3.2 Cal enviar-ho tot?</h3>
<p>Com haurem vist a l'exemple anterior, el procediment funciona be, però el rendiment no és l'adequat. Tots els processos tenen totes les dades, i el cost d'enviar tantes dades, per molt bona que siga la xarxa, hem de millorar-lo.</p>
<p>Ademès, pots observar que cada procés disposa de tres quartes part de vector que no va a fer servir. Haurem doncs de donar-li <strong>sols</strong> la part de vector que necessita</p>
<h1 id="exemple-2-c%C3%A0lcul-del-numero-pi-%CF%80">Exemple (2). Càlcul del numero PI (π)</h1>
<h2 id="4-comunicacions-avan%C3%A7ades">4 Comunicacions avançades</h2>
<p>Ja hem vist la manera bàsica de comunicar-se. Ara anem a veure maneres més eficients i optimitzades</p>
<h3 id="41-broadcast-difussi%C3%B3">4.1 Broadcast (difussió)</h3>
<p>Mitjançant el broadcast, podem enviar una variable a la resta de processos. Requeriment: La variable ha d'existir prèviament en tots el processos, en el que envia, òbviament amb el valor que volem difondre i en els que rebràn la informació amb valor <code>None</code> (null).</p>
<p><img src="./broadcasting.jpg" alt=""></p>
<p>Exemple:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> mpi4py <span class="hljs-keyword">import</span> MPI

comm = MPI.COMM_WORLD
rank = comm.Get_rank()


<span class="hljs-keyword">if</span> rank == <span class="hljs-number">0</span>:
    <span class="hljs-comment"># El que envia té la informació</span>
   data = <span class="hljs-number">34</span>;   <span class="hljs-comment">#Pot-ser qualssevol tipus i valor</span>
   <span class="hljs-comment"># data={"nom":"Pepe","edat":43}</span>
   <span class="hljs-comment"># data= [3,4,5,6,7,8]</span>
<span class="hljs-keyword">else</span>:
    <span class="hljs-comment"># El que rep te sols la variable</span>
    data = <span class="hljs-literal">None</span>

<span class="hljs-comment"># -- Difussió --</span>
data = comm.bcast(data, root=<span class="hljs-number">0</span>)

<span class="hljs-comment"># -- En totes el processos el mateix valor</span>
print(<span class="hljs-string">'Al node '</span> + str(rank): )
print(data)
</div></code></pre>
<h3 id="42-scatter-fragmentar-dispersar-dividir">4.2 Scatter (fragmentar-dispersar-dividir)</h3>
<p>Com hem vist a l'exemple de la suma dels vectors, el rendiment no era gaire adequat. Això és perquè tots els processos tenien tota la informació, i enviar la informació d'un node a altre te un cost (temporal)</p>
<p>Com hem comentat la solució és repartir a cada node sols la part de vector que necessita, i això podem aconseguir-ho amb <code>scatter</code></p>
<p>Amb el mecanisme de dispersió (<strong>scattering</strong>) el node que ho executa s'encarrega de dividir la informació, que obligatòriament haura de ser una llista (vector) i enviar-la a cadascun dels nodes que conformen el clúster</p>
<p><img src="./scatter.jpg" alt=""></p>
<p>Habitualment intentar que el tamany de la llista siga divisible pel número de nodes del clúster, així tots treballen amb la mateixa quantitat d'informació.</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> mpi4py <span class="hljs-keyword">import</span> MPI

comm = MPI.COMM_WORLD
size = comm.Get_size()
rank = comm.Get_rank()

<span class="hljs-keyword">if</span> rank == <span class="hljs-number">0</span>:
    <span class="hljs-comment"># crea el vector [1,4,9,16]</span>
   data = [(i+<span class="hljs-number">1</span>)**<span class="hljs-number">2</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(size)]
<span class="hljs-keyword">else</span>:
   data = <span class="hljs-literal">None</span>

data = comm.scatter(data, root=<span class="hljs-number">0</span>)
<span class="hljs-keyword">print</span> (<span class="hljs-string">"Soc el proces %d i he rebut: "</span>%rank)
<span class="hljs-keyword">print</span> (data)
</div></code></pre>
<blockquote>
<p>Observar que:</p>
<ul>
<li>La data que dividim és la entrada de la funció (està com a argument) i també com a eixida (a l'esquerre de l'igual). Així aconseguim que el node master dispose també de la seua porció de dades</li>
<li>el segon argument (<code>root=0</code>) indica que és el procés amb <code>rank==0</code> qui farà l'enviament d'informació, mentre que els altres sols rebran la informació.</li>
</ul>
</blockquote>
<p>Cas que l'objecte a transferir sigui algun objecte més complex o més gran, com un array de la llibreria <code>numpy</code> és convenient fer servir altra funció per a repartir.</p>
<p>Aquesta nova manera implica fer una reserva de memòria prèvia per al vector que es rebrà al destí. Vegem l'exemple:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> mpi4py <span class="hljs-keyword">import</span> MPI
<span class="hljs-keyword">import</span> numpy

comm = MPI.COMM_WORLD
size = comm.Get_size()
rank = comm.Get_rank()


tamany=<span class="hljs-number">1000</span>
bloc=tamany/size

<span class="hljs-comment"># Al master creem un vector amb numpy.</span>
<span class="hljs-comment"># arrange el crea amb la serie 1,2,3,4,5...</span>
<span class="hljs-keyword">if</span> rank == <span class="hljs-number">0</span>:
   g_data =numpy.arange(tamany,dtype=<span class="hljs-string">'i'</span>)
<span class="hljs-keyword">else</span>:
    <span class="hljs-comment"># als altres es cal la referència, </span>
    <span class="hljs-comment"># encara que no continga res</span>
   g_data = <span class="hljs-literal">None</span>

<span class="hljs-comment"># Ara preparem el vector que contindrà la porció del gran. </span>
<span class="hljs-comment"># El creem buit mitjançant empty. </span>
l_data=numpy.empty(bloc,dtype=<span class="hljs-string">'i'</span>)

<span class="hljs-comment"># Fem la divisió</span>

<span class="hljs-comment"># dividim lo global a lo local</span>
comm.Scatterv(g_data,l_data,root=<span class="hljs-number">0</span>)

<span class="hljs-comment"># ara tots els nodes processarien la seua part del vector, </span>
<span class="hljs-comment"># root també</span>
</div></code></pre>
<h3 id="43-gather-reunir">4.3 Gather (reunir)</h3>
<p>Com podreu deduir, si hem pogut fragmentar un vector en diversos més menuts, deuirem de poder reajuntar dits trossos més menuts en un global.</p>
<p><img src="./gather.jpg" alt=""></p>
<p>Per a fer-ho, un cop processats les dades o vectors el més important serà:</p>
<ul>
<li>reservar la memòria al root per a rebre tota la informació</li>
<li>Decidir com voldrem estructurar dita informació, ja que depenent de com creem la estrcutura, s'ajuntarà d'una manera o d'altra</li>
</ul>
<h4 id="431-escalar-a-vector">4.3.1 Escalar a vector</h4>
<p>En aquest cas partim de que cada node (per exemple 4) te un escalar (un valor simple). Al reunir-lo el root tindrà un vector de 4 elements</p>
<p><img src="./gather_01.png" alt=""></p>
<h4 id="432-vector-a-vector">4.3.2 Vector a vector</h4>
<p>Si en cada node tenim un vector (per exemple 4 nodes en vectors de 3 elements). Ho podem juntar tot en un gran vector (4x3=12 elements)</p>
<p><img src="./gather_02.png" alt=""></p>
<h4 id="432-jugant-en-les-dimensions">4.3.2 Jugant en les dimensions</h4>
<p>Per acabar, al reunir la informació podem jugar conforme vullguem, sempre i quant s'acomplisca la següent norma: <strong>la quantitat de dades que s'envie serà la quantitat de dades que es coloquen</strong>.</p>
<p>Si enviem 4 vectors de 3 elements (12), podem formar una matriu de 2x6 (12)</p>
<p><img src="./gather_03.png" alt=""></p>
<p>Si cada node (4) te una matriu  de 3x3 (en total hi han 4x3x3=36 dades), com podem recomposar la informació?</p>
<p><img src="./gather_04.png" alt=""></p>
<p>Con vullguem sempre que el producte de les dimensions del resultat sigui 36, inclòs una matriu de 3x3x4 o de 4x3x3, etc</p>
<p><img src="./gather_05.png" alt=""></p>
<h1 id="exemple-3-filtratge-duna-imatge-en-color">Exemple (3). Filtratge d'una imatge en color</h1>
<p><img src="imatge_color_bn.png" alt=""></p>

</body>
</html>
